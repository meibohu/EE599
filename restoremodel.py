# -*- coding: utf-8 -*-
"""restoremodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14eJVfPxnj1te9Ja6mUemZPZxuIJX2hcZ
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

!pwd
# %cd /content/gdrive/My\ Drive/EE599_finalproject_team17/

import tensorflow as tf
import numpy as np
import h5py
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import argparse
import os
import time

def IoU_metric(y_true, y_pred):
    smooth =1e-8
    y_true = np.ndarray.flatten(y_true)
    y_pred = np.ndarray.flatten(y_pred)
    intersection = np.sum(y_true * y_pred)
    # union = K.sum(K.sign(y_true_f+y_pred_f))
    union = np.sum(y_true)+ np.sum(y_pred)-intersection
    # union = K.sum(y_true_f)+ K.sum(y_pred_f)

    return intersection/union

def IOU_calc(y_true, y_pred):

    smooth =1e-6
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    union = K.sum(y_true_f)+ K.sum(y_pred_f)-intersection
    return (intersection + smooth) / (union + smooth)


def IOU_calc_loss(y_true, y_pred):
    return 1.-IOU_calc(y_true, y_pred)

def focal_loss(gamma=2., alpha=.25):
    def focal_loss_fixed(y_true, y_pred):
        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
        return -tf.mean(alpha * tf.pow(1. - pt_1, gamma) * tf.log(pt_1)) - tf.mean((1 - alpha) * tf.pow(pt_0, gamma) * tf.log(1. - pt_0))
    return focal_loss_fixed

def weighted_bce(y_true, y_pred):
    weights = (y_true * 5.) + 1.
    bce = K.binary_crossentropy(y_true, y_pred)
    weighted_bce = K.mean(bce * weights)
    return weighted_bce

def my_loss(y_true, y_pred):
#     loss = K.binary_crossentropy(y_true,y_pred)*0.1 + IOU_calc_loss(y_true, y_pred)
#     loss = K.binary_crossentropy(y_true,y_pred)+ tfa.losses.SigmoidFocalCrossEntropy()*0.5
#     loss = tfa.losses.GIoULoss(mode='iou')
#     loss = tfa.losses.sigmoid_focal_crossentropy()
    loss = weighted_bce(y_true, y_pred)*0.1 + IOU_calc_loss(y_true, y_pred)

    return loss

test_img_dir = '/content/gdrive/My Drive/EE599_finalproject_team17/data/test_org.hdf5'
test_msk_dir = '/content/gdrive/My Drive/EE599_finalproject_team17/data/test_msk.hdf5'
model_dir = '/content/gdrive/My Drive/EE599_finalproject_team17/g_model_5epo_Gunet_0605917.h5'

# load test dataset
import h5py,os, json
with h5py.File(test_img_dir, 'r') as hf:
  print(hf.keys())
  test_imgs = hf['test_data'][:]
  # test_imgs = test_imgs[:4]
  print(test_imgs.shape)
with h5py.File(test_msk_dir, 'r') as hf:
  print(hf.keys())
  test_mask = hf['test_mask'][:]
  # test_mask = test_mask[:4]
  print(test_mask.shape)



# load the g_model
test_model = tf.keras.models.load_model(model_dir, custom_objects={'IOU_calc_loss':IOU_calc_loss,'IOU_calc':IOU_calc,'weighted_bce':weighted_bce,'my_loss':my_loss})

# test_model = tf.keras.models.load_model(model_dir, custom_objects={'IOU_calc_loss':IOU_calc_loss,'IOU_calc':IOU_calc,'weighted_bce':weighted_bce,'my_loss':my_loss})
test_model.summary()

# predict
import time
predict = np.zeros((test_mask.shape[0],test_mask.shape[1],test_mask.shape[2],test_mask.shape[3]))
for i in range(0,test_mask.shape[0]):
  
  # GAN model
  start = time.time()
  predict[i:i+1,:,:,:] = test_model(test_imgs[i:i+1,:,:,:])
  end = time.time()
  during = end-start
  # tiramisu model
  # predict[i:i+1,:,:,:] = test_model.predict(test_imgs[i:i+1,:,:,:])
  
  print('infer time = %f'%during)

print(predict.shape)

# bianarization
threshold = 0.5
bi_predict = np.where(predict>threshold, 1, 0)
np.save('bi_predict',bi_predict)

# compute the mean iou of human
total_iou = 0
for i in range(0,bi_predict.shape[0]):
  total_iou = total_iou + IoU_metric(test_mask[i],bi_predict[i])
  print('#%f test_sample IoU= %f'%(i,IoU_metric(test_mask[i],bi_predict[i])))

mean_iou = total_iou/bi_predict.shape[0]
print('Mean_IoU = %f'%mean_iou)


# create the final background removal image
bk_rm_imgs = np.zeros((test_imgs.shape[0],test_imgs.shape[1],test_imgs.shape[2],test_imgs.shape[3]))
for i in range(0,bi_predict.shape[0]):
  bk_rm_imgs[i] =  np.multiply(bi_predict[i], test_imgs[i]) + (1 - bi_predict[i])

# plot the masks
import pylab
pylab.rcParams['figure.figsize'] = (16,8)

for i in range(0,bi_predict.shape[0]):
  # plt.figure()
  t = bi_predict[i]*255
  t = np.squeeze(t)
  plt.subplot(1, 4, 1)
  plt.imshow(t,cmap ='gray')

  # plt.figure()
  s = test_mask[i]*255
  s = np.squeeze(s)
  plt.subplot(1, 4, 2)
  plt.imshow(s,cmap ='gray')

  u = bk_rm_imgs[i]
  # u = np.squeeze(u)
  plt.subplot(1, 4, 3)
  plt.imshow(u)

  w = test_imgs[i]
  plt.subplot(1, 4, 4)
  plt.imshow(w)

  plt.figure()

# make the background removal image output



# import pylab
# pylab.rcParams['figure.figsize'] = (5,5)


# plt.figure()
# t = predict[0,:,:]*255
# t = np.squeeze(t)
# plt.imshow(t,cmap ='gray')
# plt.figure()
# t = predict[1,:,:]*255
# t = np.squeeze(t)

# plt.imshow(t,cmap ='gray')
# plt.figure()
# t = predict[2,:,:]*255
# t = np.squeeze(t)

# plt.imshow(t,cmap ='gray')
# plt.figure()
# t = predict[3,:,:]*255
# t = np.squeeze(t)

# plt.imshow(t,cmap ='gray')
# plt.figure()
# t = predict[4,:,:]*255
# t = np.squeeze(t)

# plt.imshow(t,cmap ='gray')

# import numpy as np
# a = np.random.random((3,3))
# threshold = 0.5
# b = np.where(a>threshold, 1, 0)
# print(a)
# print(b)